{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d410c7a-647f-4e33-a1b5-8f98f6e7c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\thaya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import Attention\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1413d6ed-379b-48aa-a05a-71a08a2c3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TamilSummarization.csv\")  \n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3c7c6d-0319-4e42-bcad-229225555aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = data['Text']\n",
    "summary_data = data['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bb20c6-cf36-423a-93de-f3f1ee72cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = 100\n",
    "max_summary_len = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f518e74-b5cc-4e1f-a41f-559ae124db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = data['Summary'].apply(lambda x: 'start ' + x + ' end')\n",
    "text_tokenizer = Tokenizer()\n",
    "text_tokenizer.fit_on_texts(text_data)\n",
    "text_sequences = text_tokenizer.texts_to_sequences(text_data)\n",
    "text_vocab_size = len(text_tokenizer.word_index) + 1\n",
    "\n",
    "summary_tokenizer = Tokenizer()\n",
    "summary_tokenizer.fit_on_texts(summary_data)\n",
    "summary_sequences = summary_tokenizer.texts_to_sequences(summary_data)\n",
    "summary_vocab_size = len(summary_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b15235-543d-4299-990c-01cdedcd0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "text_sequences = pad_sequences(text_sequences, maxlen=max_text_len, padding='post')\n",
    "summary_sequences = pad_sequences(summary_sequences, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(text_sequences, summary_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "embedding_dim = 100\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "enc_emb = Embedding(text_vocab_size, embedding_dim, trainable=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Attention Layer\n",
    "attention = Attention()([encoder_outputs, encoder_outputs])\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(summary_vocab_size, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense Layer\n",
    "decoder_dense = Dense(summary_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a90b23d-4234-40f7-9986-b7ade2a90b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 12s 2s/step - loss: 6.3263 - accuracy: 0.2589 - val_loss: 6.2847 - val_accuracy: 0.5595\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 708ms/step - loss: 6.2663 - accuracy: 0.5560 - val_loss: 6.1784 - val_accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 6.1054 - accuracy: 0.5560 - val_loss: 5.4548 - val_accuracy: 0.5595\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 795ms/step - loss: 4.8815 - accuracy: 0.5560 - val_loss: 3.5275 - val_accuracy: 0.5595\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 765ms/step - loss: 3.3259 - accuracy: 0.5560 - val_loss: 3.0714 - val_accuracy: 0.5595\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 744ms/step - loss: 2.9948 - accuracy: 0.5560 - val_loss: 3.0256 - val_accuracy: 0.5595\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 767ms/step - loss: 2.9077 - accuracy: 0.5560 - val_loss: 2.9737 - val_accuracy: 0.5595\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 707ms/step - loss: 2.8339 - accuracy: 0.5560 - val_loss: 2.9668 - val_accuracy: 0.5595\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 582ms/step - loss: 2.7510 - accuracy: 0.5560 - val_loss: 2.9634 - val_accuracy: 0.5595\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 726ms/step - loss: 2.7050 - accuracy: 0.5565 - val_loss: 3.0261 - val_accuracy: 0.5619\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 10  \n",
    "\n",
    "history = model.fit(\n",
    "    [X_train, y_train[:, :-1]],\n",
    "    y_train[:, 1:],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=([X_val, y_val[:, :-1]], y_val[:, 1:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce6a968e-1f1b-4af7-af12-9fb21d6b1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tamil_text_summarization_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0f3c02-49fd-4a55-bc84-e623b4c36e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Model\n",
    "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
    "    dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
    ")\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs, decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2, state_h2, state_c2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413c09b6-b762-4369-ae2c-f07a42ed9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    encoder_outs, state_h, state_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = summary_tokenizer.word_index['start']  # Correctly added 'start' token\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq, encoder_outs, state_h, state_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        # Get sampled word\n",
    "        sampled_token = summary_tokenizer.index_word.get(sampled_token_index, '')  # Gracefully handle missing indices\n",
    "        if sampled_token == 'end' or len(decoded_sentence.split()) >= max_summary_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Update target sequence\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        state_h, state_c = h, c\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64d59798-659c-46de-b32e-6ee082cd29bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Generated Summary: \n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_text = \"அரசர்கள் ஆளும் நாடுகளில் மக்கள் அமைதியாக வாழ்ந்தனர்.\"\n",
    "test_seq = pad_sequences(text_tokenizer.texts_to_sequences([test_text]), maxlen=max_text_len, padding='post')\n",
    "summary = decode_sequence(test_seq)\n",
    "print(\"Generated Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2525d9-f459-4d83-8e37-e80fdc789089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
